# Synthetic-Speech-Using-Text-to-Speech

## In this lab you use the Text-to-Speech API to do the following:

1. Create a series of audio files

2. Listen and compare audio files

3. Configure audio output

## Understanding the results
In the results for your video annotation, Vertex AI provides three types of information:

Labels for the video: This information is on the Segment tab below the video on the results page.

Labels for shots within the video: This information is on the Shot tab below the video on the results page.

Labels for each 1-second interval within the video: This information is on the Interval tab below the video on the results page.

If the prediction fails, the results in the list show a red icon on the Recent Predictions list.

If only one video in the prediction attempt failed, the results show a green icon in the Recent Predictions list. On the results page for that prediction, you can view the results for the videos that Vertex AI has annotated.
